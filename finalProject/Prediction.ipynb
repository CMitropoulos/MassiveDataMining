{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image, HTML\n",
    "import json\n",
    "import datetime\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prediction of Revenue</h2>\n",
    "Features Description:\n",
    "\n",
    "- belongs_to_collection will be turned into a Boolean variable. 1 indicates a movie is a part of collection whereas 0 indicates it is not.\n",
    "- homepage will be converted into a Boolean variable that will indicate if a movie has a homepage or not.\n",
    "- original_language will be replaced by a feature called is_foreign to denote if a particular film is in English or a Foreign Language.\n",
    "- production_countries will be replaced with the number of countries the film was shot in.\n",
    "- day will be converted into a binary feature to indicate if the film was released on a Friday.\n",
    "- month will be converted into a variable that indicates if the month was a holiday season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['belongs_to_collection'] = df['belongs_to_collection'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "    df['homepage'] = df['homepage'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "    df['is_english'] = df['original_language'].apply(lambda x: 1 if x=='en' else 0)\n",
    "    df = df.drop('original_language', axis=1)\n",
    "    \n",
    "    '''for prod_comp in prod_companies_freq.keys():\n",
    "        if prod_companies_freq[prod_comp]>290:\n",
    "            df['is_popular_production'] = df['production_companies'].apply(lambda x: 1 \n",
    "                                                                          if prod_comp in x \n",
    "                                                                          else 0 )\n",
    "            break'''\n",
    "    \n",
    "    for prod_comp in prod_companies_freq.keys():\n",
    "        if prod_companies_freq[prod_comp]<40:\n",
    "            df['is_non-popular_production'] = df['production_companies'].apply(lambda x: 1 \n",
    "                                                                          if prod_comp in x \n",
    "                                                                          else 0 )\n",
    "            break\n",
    "    \n",
    "    for genre in genres_freq.keys():\n",
    "        if genres_freq[genre]>100:\n",
    "            df['is_' + str(genre)] = df['genres'].apply(lambda x: 1 \n",
    "                                                        if genre in x \n",
    "                                                        else 0)\n",
    "            \n",
    "    \n",
    "    '''for director in director_freq.keys():\n",
    "        if director_freq[director]>16:\n",
    "            df['is_popular_director' ] = df['director'].apply(lambda x: 11 \n",
    "                                                             if  x==director \n",
    "                                                             else 0)\n",
    "            break'''\n",
    "    \n",
    "    for director in director_freq.keys():\n",
    "        if director_freq[director]<4:\n",
    "            df['is_non-popular_director'] = df['director'].apply(lambda x: 11 \n",
    "                                                             if  x==director \n",
    "                                                             else 0)\n",
    "            break\n",
    "                                                    \n",
    "                                                    \n",
    "   \n",
    "    df['production_countries'] = df['production_countries'].apply(lambda x: len(x))\n",
    "    df['is_Friday'] = df['day'].apply(lambda x: 1 if x=='Fri' else 0)\n",
    "    df = df.drop('day', axis=1)\n",
    "    df['is_Holiday'] = df['month'].apply(lambda x: 1 if x in ['Apr', 'May', 'Jun', 'Nov'] else 0)\n",
    "    df = df.drop('month', axis=1)\n",
    "    df = df.drop(['title', 'cast', 'director', 'homepage'], axis=1)\n",
    "    #df = df.drop(['title'], axis=1)\n",
    "    #df = pd.get_dummies(df, prefix='is')\n",
    "    df['runtime'] = df['runtime'].fillna(df['runtime'].mean())\n",
    "    df['vote_average'] = df['vote_average'].fillna(df['vote_average'].mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validation Scores : {'Extra Trees Regressor': 0.7290039607489605, 'K-NN': 0.6619803039234805, 'Linear Regression': 0.7302002358786033, 'Random Forest Regressor': 0.7599668917781968, 'Adaboost Regressor': 0.3239453147661841, 'Gradient Boosting Regressor': 0.7760829930634865}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reading the pre engineered file\n",
    "X_pre = pd.read_csv('X_predict_pre_engineered.csv')\n",
    "y = pd.read_csv('y_predict.csv')\n",
    "\n",
    "del X_pre['Unnamed: 0']\n",
    "#create lists\n",
    "X_pre['genres'] = X_pre['genres'].apply(lambda x:ast.literal_eval(x) )\n",
    "X_pre['production_companies'] = X_pre['production_companies'].apply(lambda x:ast.literal_eval(x) )\n",
    "\n",
    "\n",
    "#find frequency of prod companies\n",
    "prod_companies_freq = defaultdict(int)\n",
    "def find_freq_prod_comp(prod_comp_list):\n",
    "    for item in prod_comp_list: \n",
    "            prod_companies_freq[item]+=1\n",
    "\n",
    "#find frequency of genres\n",
    "genres_freq = defaultdict(int)\n",
    "def find_freq_genres(genre_list):\n",
    "    for item in genre_list:\n",
    "        genres_freq[item]+=1\n",
    "            \n",
    "#find frequency of directors           \n",
    "director_freq = defaultdict(int)\n",
    "def find_freq_directors(item):\n",
    "    director_freq[item]+=1\n",
    "            #print(item)\n",
    "\n",
    "actor_freq = defaultdict(int)\n",
    "def find_freq_actors(item):\n",
    "    actor_freq[item]+=1\n",
    "            #print(item)\n",
    "\n",
    "        \n",
    "X_pre['production_companies'].apply(find_freq_prod_comp)\n",
    "X_pre['genres'].apply(find_freq_genres)\n",
    "X_pre['director'].apply(find_freq_directors)\n",
    "X_pre['cast_size']\n",
    "\n",
    "#genres_train = X_pre['genres'].drop_duplicates()\n",
    "X_pre = feature_engineering(X_pre)\n",
    "X_pre = X_pre.select_dtypes(include=[np.float64, np.int64])\n",
    "#X = X.reset_index()\n",
    "X_pre.to_csv('X_feature_engireered.csv', index=False)\n",
    "\n",
    "print()\n",
    "#(sorted(director_freq.items(), key=lambda kv: kv[1], reverse=True) )\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_pre, y, test_size=0.1, random_state=42)\n",
    "\n",
    "ESTIMATORS = {\n",
    "    \"Extra Trees Regressor\": ExtraTreesRegressor(n_estimators=5,\n",
    "                                       random_state=0),\n",
    "    \"K-NN\": KNeighborsRegressor(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\" : RandomForestRegressor(), \n",
    "    \"Adaboost Regressor\" :AdaBoostRegressor(),\n",
    "    \"Gradient Boosting Regressor\":  GradientBoostingRegressor(),\n",
    "}\n",
    "\n",
    "cv_score = {}\n",
    "test_score = {}\n",
    "for name, estimator in ESTIMATORS.items():\n",
    "    pipe = Pipeline([('Robust Scaler', RobustScaler()), (name, estimator)])\n",
    "    #np.ravel(y_train,order='C')\n",
    "    pipe.fit(X_train, y_train)\n",
    "    cv_score[name]= sum(cross_val_score(pipe, X_train, y_train, cv=10))/10\n",
    "    test_score[name] = pipe.score(X_test, y_test)\n",
    "    #print(name)\n",
    "    #print(\"Test Score\"+\" : \"+str(estimator.score(X_test, y_test)))\n",
    "    #print(\"Validation Score\"+\" : \"+str(estimator.score(X_val, y_val)))  \n",
    "print(\"Cross Validation Scores\"+\" : \"+ str(cv_score) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sorted(director_freq.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_score_list = sorted(cv_score.items(), key=lambda kv: kv[1], reverse=True)\n",
    "#print(\"Cross Validation Scores\"+\" : \"+ str(cv_score_list) + \"\\n\")\n",
    "x1, y1 = zip(*cv_score_list)\n",
    "plt.bar(range(len(x1)),y1,  color='green' )\n",
    "plt.xticks(range(len(x1)),x1, rotation='vertical')\n",
    "plt.title('Average regression score on 10-fold cross validation')\n",
    "plt.ylim([0,1])\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_list = sorted(test_score.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(\"Test Scores\"+\" : \"+str(test_score_list) + \"\\n\")\n",
    "\n",
    "x1, y1 = zip(*test_score_list)\n",
    "plt.bar(range(len(x1)),y1,  color='red' )\n",
    "plt.xticks(range(len(x1)),x1, rotation='vertical')\n",
    "plt.title('Testing Scores')\n",
    "plt.ylim([0,1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_pre['crew_size'], y)\n",
    "plt.ylim([0,max(y)])\n",
    "plt.yticks([])#np.arange(0, max(y['revenue']), step=100))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> CLASSIFICATION INTO REVENUE CATEGORIES </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We will create classes in order to classify the movie into revenue categories and not predict an exact revenue\n",
    "This might be more practical for real agencies</h3>\n",
    "\n",
    "Main classes are:\n",
    "    - revenue < 50 mil dollars\n",
    "    - 50 mil < revenue < 100 mil\n",
    "    - 100 mil < revenue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./predict/X_feature_engireered.csv')\n",
    "y = pd.read_csv('./predict/y_predict.csv')\n",
    "#Rescale y into millions\n",
    "y['revenue'] = y['revenue'].apply(lambda x: int(x/10E6))\n",
    "#y['revenue'] = y['revenue'].apply(lambda x: round(x,-1))\n",
    "#plt.plot( np.linspace(0, y.size-1,y.size )-1, y, 'go')\n",
    "\n",
    "#CREATE THE LABELS FOR THE CLASSIFICATION\n",
    "y['labels'] = y['revenue'].apply(lambda x: 0 if x<25 # else 1)\n",
    "                                             else (1 if x<50  # else 2))\n",
    "                                                   else( 2 if x<75 else ( 3 if x <100 else 4))))\n",
    "y['revenue'].hist(bins=55)\n",
    "y = y.drop('revenue', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.1, random_state=42)\n",
    "y_train = np.ravel(y_train,order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CLASSIFIERS = {\n",
    "    \"Nearest Neighbors\" : KNeighborsClassifier(5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "    \"Random Forest\" :  RandomForestClassifier(max_depth=5, n_estimators=10, max_features=2),\n",
    "    \"Neural Net\" :     MLPClassifier(alpha=1),\n",
    "    \"AdaBoost\" : AdaBoostClassifier(), \n",
    "    \"Naive Bayes\" :GaussianNB(),\n",
    "    #\"QDA\" :QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in CLASSIFIERS.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(name)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Test : \"+ str(score))\n",
    "    score = clf.score(X_val, y_val)\n",
    "    print(\"validation : \"+ str(score))\n",
    "    score = clf.score(X_train, y_train)\n",
    "    print(\"Train : \"+ str(score))\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Voting classifier </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiers= [ \n",
    "clf1 = KNeighborsClassifier(5)\n",
    "clf2 =  DecisionTreeClassifier(max_depth=5)\n",
    "clf3 = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=2)\n",
    "clf4 = MLPClassifier(alpha=1)\n",
    "clf5 = AdaBoostClassifier()\n",
    "clf6 = GaussianNB()\n",
    "#]\n",
    "names = [\"Nearest Neighbors\", \n",
    "          \"Decision Tree\",\n",
    "         \"Random Forest\", \n",
    "         \"Neural Net\", \n",
    "         \"AdaBoost\",\n",
    "         \"Naive Bayes\",\n",
    "        ]\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "clf3 = clf3.fit(X_train, y_train)\n",
    "clf4 = clf4.fit(X_train, y_train)\n",
    "clf5 = clf5.fit(X_train, y_train)\n",
    "clf6 = clf6.fit(X_train, y_train)\n",
    "weights = [clf1.score(X_train, y_train), clf2.score(X_train, y_train), \n",
    "          clf3.score(X_train, y_train), clf4.score(X_train, y_train),\n",
    "          clf5.score(X_train, y_train), clf6.score(X_train, y_train)]\n",
    "\n",
    "eclf = VotingClassifier(estimators=\n",
    "                        [(\"Nearest Neighbors\", clf1), (\"Decision Tree\", clf2),\n",
    "                         (\"Random Forest\", clf3), \n",
    "                        (\"NN\", clf4), (\"Adaboost\", clf5),\n",
    "                         (\"Naive Bayes\", clf6)], voting='soft', weights=weights)\n",
    "eclf = eclf.fit(X_train, y_train)\n",
    "score = eclf.score(X_val, y_val)\n",
    "print(\"validation : \"+ str(score))\n",
    "score = eclf.score(X_train, y_train)\n",
    "print(\"Train : \"+ str(score))\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "# load pima indians dataset\n",
    "X = pd.read_csv('./predict/X_feature_engireered.csv')\n",
    "y = pd.read_csv('./predict/y_predict.csv')\n",
    "X = X.as_matrix()\n",
    "y = y.as_matrix()\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(X.shape[1],), init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "#model.add(Dense(12, init='uniform', activation='sigmoid'))\n",
    "#model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 3\n",
    "import keras\n",
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)\n",
    "\n",
    "# 4\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, batch_size=50,  verbose=1, validation_split=0.3)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
